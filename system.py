import cv2
import numpy as np
import serial
import time
from datetime import datetime
import threading
import queue
import os
from ultralytics import YOLO

# ========================= 
# ESP32 CONFIG
# ========================= 
ESP32_PORT = 'COM3'
ESP32_BAUDRATE = 115200
TRIGGER_COMMAND = 'CAPTURE'

# ========================= 
# VIDEO & SNAPSHOT CONFIG
# ========================= 
VIDEO_FOLDER = "D:/med_project/recordings/"
SNAPSHOT_FOLDER = "D:/med_project/snapshots/"
VIDEO_FPS = 30
VIDEO_CODEC = cv2.VideoWriter_fourcc(*'mp4v')

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
os.makedirs(VIDEO_FOLDER, exist_ok=True)
os.makedirs(SNAPSHOT_FOLDER, exist_ok=True)

# ========================= 
# LEVEL CONFIG
# ========================= 
LEVEL_THICKNESS = 2
LEVEL_COUNT = 6  # ‡∏°‡∏µ 5 ‡πÄ‡∏™‡πâ‡∏ô = 6 ‡∏ä‡πà‡∏≠‡∏á (0-5)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Y ‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏™‡πâ‡∏ô (‡∏à‡∏≤‡∏Å‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á)
LEVEL_Y_POSITIONS = [300, 450, 600, 750, 900]

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Level (BGR format)
LEVEL_COLORS = {
    5: (0, 255, 0),      # L5 - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
    4: (255, 100, 240),  # L4 - ‡∏°‡πà‡∏ß‡∏á
    3: (0, 255, 255),    # L3 - ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
    2: (255, 255, 0),    # L2 - ‡∏ü‡πâ‡∏≤
    1: (0, 0, 255),      # L1 - ‡πÅ‡∏î‡∏á
}

LEVEL_COUNT_COLOR = (0, 255, 255)  # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç

# =========================
# LEVEL SCORE CONFIG
# =========================
LEVEL_SCORES = {
    0: 0,
    1: 1,
    2: 2,
    3: 3,
    4: 4,
    5: 5
}

# =========================
# TOTAL FLY COUNT INPUT (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô)
# =========================
TOTAL_FLIES_PER_TUBE = [
    0,  # Tube 1
    0,  # Tube 2
    0,  # Tube 3
    0,  # Tube 4
    0   # Tube 5
]

# =========================
# TUBE CONFIGS
# =========================
TUBE_CONFIGS = [
    {'offset_from_left': 280,  'width': 200, 'top_offset': 40, 'bottom_offset': 3},
    {'offset_from_left': 540,  'width': 200, 'top_offset': 40, 'bottom_offset': 3},
    {'offset_from_left': 815,  'width': 200, 'top_offset': 40, 'bottom_offset': 3},
    {'offset_from_left': 1095, 'width': 200, 'top_offset': 40, 'bottom_offset': 3},
    {'offset_from_left': 1375, 'width': 215, 'top_offset': 40, 'bottom_offset': 3},
]

# ‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö tube borders (BGR format) - ‡∏™‡∏µ‡∏™‡∏ß‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏µ‡∏î‡∏≥
colors = [
    (0, 0, 0),  # Tube 1 - 
    (0, 0, 0),  # Tube 2 - 
    (0, 0, 0),  # Tube 3 - 
    (0, 0, 0),  # Tube 4 -
    (0, 0, 0),  # Tube 5 - 
]

# =========================
# SIDEBAR CONFIG
# =========================
SIDEBAR_WIDTH = 400
SIDEBAR_COLOR = (210, 210, 210)  # ‡∏™‡∏µ‡πÄ‡∏ó‡∏≤‡πÄ‡∏Ç‡πâ‡∏°

# =========================
# YOLO CONFIG
# =========================
YOLO_MODEL_PATH = 'yolo26n_v2.pt'  # path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á trained model
YOLO_CONF_THRESHOLD = 0.65  # confidence threshold
YOLO_INPUT_SIZE = 640  # ‡∏Ç‡∏ô‡∏≤‡∏î input ‡∏Ç‡∏≠‡∏á YOLO
OVERLAP_PERCENT = 0.5  # overlap 50%

# =========================
# LOAD YOLO MODEL
# =========================
try:
    yolo_model = YOLO(YOLO_MODEL_PATH)
    print(f"‚úì Loaded YOLO model from: {YOLO_MODEL_PATH}")
except Exception as e:
    print(f"‚úó Error loading YOLO model: {e}")
    print("  ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OpenCV Threshold method")
    yolo_model = None

# ========================= 
# GLOBAL VARIABLES
# ========================= 
trigger_queue = queue.Queue()
waiting_for_5sec_capture = False
capture_5sec_time = 0
WAIT_DURATION = 5  # ‡∏£‡∏≠ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÅ‡∏£‡∏Å

# ========================= 
# ESP32 SERIAL READER THREAD
# ========================= 
def read_esp32(ser, trigger_queue):
    """‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ESP32 ‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å"""
    print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ESP32...")
    while True:
        try:
            if ser.in_waiting > 0:
                line = ser.readline().decode('utf-8').strip()
                print(f"ESP32: {line}")
                if TRIGGER_COMMAND in line:
                    trigger_queue.put(True)
                    print(">>> ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å ESP32!")
        except Exception as e:
            print(f"Error reading ESP32: {e}")
            time.sleep(0.1)

# =========================
# YOLO HELPER FUNCTIONS
# =========================
def create_level_crops(tube_roi, tube_y_start, x_start):
    """‡πÅ‡∏ö‡πà‡∏á tube ‡πÄ‡∏õ‡πá‡∏ô crops ‡∏ï‡∏≤‡∏° levels ‡πÇ‡∏î‡∏¢‡∏°‡∏µ overlap"""
    h, w = tube_roi.shape[:2]
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ tube_roi ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á
    if h == 0 or w == 0:
        return []
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á level ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡πÉ‡∏ô process_frame
    LEVEL_Y_DRAW = [y - 50 for y in LEVEL_Y_POSITIONS]  # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏†‡∏≤‡∏û
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô relative position ‡πÉ‡∏ô tube ROI
    LEVEL_Y_IN_TUBE = []
    for y in LEVEL_Y_DRAW:
        y_relative = y - tube_y_start
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô tube
        if 0 < y_relative < h:
            LEVEL_Y_IN_TUBE.append(int(y_relative))
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ level ‡πÉ‡∏ô tube ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ whole tube
    if len(LEVEL_Y_IN_TUBE) == 0:
        crop_img = tube_roi.copy()
        if crop_img.size > 0:
            return [{
                'img': crop_img,
                'y_start': 0,
                'y_end': h,
                'level': 0,
                'original_y_start': 0,
                'original_y_end': h
            }]
        else:
            return []
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° boundary ‡∏ó‡∏µ‡πà top ‡πÅ‡∏•‡∏∞ bottom
    boundaries = [0] + LEVEL_Y_IN_TUBE + [h]
    
    crops = []
    
    for i in range(len(boundaries) - 1):
        y_start = int(boundaries[i])
        y_end = int(boundaries[i + 1])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î
        if y_end <= y_start:
            continue
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì overlap
        crop_height = y_end - y_start
        overlap_pixels = int(crop_height * OVERLAP_PERCENT)
        
        # ‡∏Ç‡∏¢‡∏≤‡∏¢ crop ‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏•‡∏á
        crop_y_start = max(0, y_start - overlap_pixels)
        crop_y_end = min(h, y_end + overlap_pixels)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á overlap
        if crop_y_end <= crop_y_start:
            continue
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏Å‡∏û‡∏≠ (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10 pixels)
        if (crop_y_end - crop_y_start) < 10:
            continue
        
        # crop ‡∏†‡∏≤‡∏û
        crop_img = tube_roi[crop_y_start:crop_y_end, :].copy()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ crop ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á
        if crop_img.size == 0 or crop_img.shape[0] == 0 or crop_img.shape[1] == 0:
            continue
        
        # ‡∏£‡∏∞‡∏ö‡∏∏ level
        level_num = len(boundaries) - 2 - i
        
        crops.append({
            'img': crop_img,
            'y_start': crop_y_start,
            'y_end': crop_y_end,
            'level': level_num,
            'original_y_start': y_start,
            'original_y_end': y_end
        })
    
    return crops

def resize_to_yolo_input(img, target_size=640):
    """Resize image to YOLO input size with padding"""
    if img is None or img.size == 0:
        return None, None, None, None
    
    h, w = img.shape[:2]
    
    if h == 0 or w == 0:
        return None, None, None, None
    
    scale = target_size / max(h, w)
    new_w = int(w * scale)
    new_h = int(h * scale)
    
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î 0
    if new_w == 0 or new_h == 0:
        return None, None, None, None
    
    resized = cv2.resize(img, (new_w, new_h))
    
    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)
    
    y_offset = (target_size - new_h) // 2
    x_offset = (target_size - new_w) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas, scale, x_offset, y_offset

def detect_flies_yolo(crop_info, conf_threshold=0.25):
    """‡πÉ‡∏ä‡πâ YOLO detect ‡πÅ‡∏°‡∏•‡∏á‡∏ß‡∏±‡∏ô‡πÉ‡∏ô crop"""
    if yolo_model is None:
        return []
    
    crop_img = crop_info['img']
    
    if crop_img is None or crop_img.size == 0:
        return []
    
    # Resize to YOLO input
    result = resize_to_yolo_input(crop_img, YOLO_INPUT_SIZE)
    
    if result[0] is None:  # ‡∏ñ‡πâ‡∏≤ resize ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        return []
    
    yolo_input, scale, x_offset, y_offset = result
    
    # Run YOLO detection
    results = yolo_model(yolo_input, conf=conf_threshold, verbose=False)
    
    detections = []
    
    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = box.conf[0].cpu().numpy()
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á crop coordinate
            x1_orig = int((x1 - x_offset) / scale)
            y1_orig = int((y1 - y_offset) / scale)
            x2_orig = int((x2 - x_offset) / scale)
            y2_orig = int((y2 - y_offset) / scale)
            
            if x1_orig < 0 or y1_orig < 0:
                continue
            
            w = x2_orig - x1_orig
            h = y2_orig - y1_orig
            
            detections.append({
                'x': x1_orig,
                'y': y1_orig,
                'w': w,
                'h': h,
                'conf': conf
            })
    
    return detections

def remove_duplicates(all_detections, iou_threshold=0.5):
    """‡∏•‡∏ö detection ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ NMS"""
    if len(all_detections) == 0:
        return []
    
    boxes = []
    scores = []
    
    for det in all_detections:
        x, y, w, h = det['x'], det['y'], det['w'], det['h']
        boxes.append([x, y, x+w, y+h])
        scores.append(det['conf'])
    
    boxes = np.array(boxes)
    scores = np.array(scores)
    
    indices = cv2.dnn.NMSBoxes(
        boxes.tolist(),
        scores.tolist(),
        score_threshold=0.0,
        nms_threshold=iou_threshold
    )
    
    filtered = []
    if len(indices) > 0:
        for i in indices.flatten():
            filtered.append(all_detections[i])
    
    return filtered

# ========================= 
# PROCESS FRAME FUNCTION
# ========================= 
def process_frame(img):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß + ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    orig = img.copy()
    h_img, w_img = img.shape[:2]
    
    # WHITE MASK
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_white = np.array([0, 0, 160])
    upper_white = np.array([180, 50, 255])
    white_mask = cv2.inRange(hsv, lower_white, upper_white)
    kernel_white = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
    white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, kernel_white)
    
    # BASELINE DETECTION
    roi_y_start = 0
    roi_y_end = 1000
    
    # TUBE POSITIONS
    tube_positions = []
    for i, cfg in enumerate(TUBE_CONFIGS):
        x_start = cfg['offset_from_left']
        x_end = x_start + cfg['width']
        tube_positions.append({
            'tube_num': i + 1,
            'x_start': x_start,
            'x_end': x_end
        })
    
    # ANALYZE EACH TUBE
    fly_counts = []
    tube_level_results = []
    tube_level_scores = []
    flies_above_L1 = 0
    
    LEVEL_Y_DRAW = [y - 50 for y in LEVEL_Y_POSITIONS]
    
    for i, tube in enumerate(tube_positions):
        cfg = TUBE_CONFIGS[i]
        x_start = tube['x_start']
        x_end = tube['x_end']
        tube_y_start = roi_y_start + cfg['top_offset']
        tube_y_end = roi_y_end - cfg['bottom_offset']
        
        level_counts = [0] * LEVEL_COUNT
        tube_fly_count = 0
        
        # draw tube
        cv2.rectangle(orig, (x_start, tube_y_start), (x_end, tube_y_end), colors[i], 2)
        cv2.putText(orig, f"Tube {i+1}", (x_start + 50, tube_y_start - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, colors[i], 2)
        
        # extract ROI
        tube_roi = img[tube_y_start:tube_y_end, x_start:x_end]
        
        if tube_roi.size > 0:
            gray_roi = cv2.cvtColor(tube_roi, cv2.COLOR_BGR2GRAY)
            blur_roi = cv2.GaussianBlur(gray_roi, (3, 3), 0)
            th_roi = cv2.adaptiveThreshold(
                blur_roi, 255,
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY_INV, 17, 7
            )
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            th_clean = cv2.morphologyEx(th_roi, cv2.MORPH_OPEN, kernel, iterations=2)
            
            contours_fly, _ = cv2.findContours(
                th_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )[-2:]
            
            for cnt in contours_fly:
                area = cv2.contourArea(cnt)
                if 20 < area < 200:
                    tube_fly_count += 1
                    fx, fy, fw, fh = cv2.boundingRect(cnt)
                    actual_x = x_start + fx
                    actual_y = tube_y_start + fy
                    
                    # draw fly
                    cv2.rectangle(orig, (actual_x, actual_y),
                                (actual_x + fw, actual_y + fh), (0, 0, 255), 1)
                    
                    # LEVEL CALC
                    cy = actual_y + fh // 2
                    
                    # ‡∏ô‡∏±‡∏ö‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ L1
                    if cy < LEVEL_Y_DRAW[4]:
                        flies_above_L1 += 1
                    
                    # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÑ‡∏´‡∏ô
                    assigned = False
                    for lv_idx in range(len(LEVEL_Y_DRAW)):
                        if cy < LEVEL_Y_DRAW[lv_idx]:
                            level_counts[5 - lv_idx] += 1
                            assigned = True
                            break
                    
                    if not assigned:
                        level_counts[0] += 1
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö L5 (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤)
        total_expected = TOTAL_FLIES_PER_TUBE[i] if i < len(TOTAL_FLIES_PER_TUBE) else 0
        if total_expected > 0 and tube_fly_count < total_expected:
            unseen_flies = total_expected - tube_fly_count
            level_counts[5] += unseen_flies
        
        # draw level lines
        for lv_idx, y_draw in enumerate(LEVEL_Y_DRAW):
            display_level = 5 - lv_idx
            cv2.line(orig, (x_start, y_draw), (x_end, y_draw),
                    LEVEL_COLORS[display_level], LEVEL_THICKNESS)
            
            if i == 4:  # ‡∏´‡∏•‡∏≠‡∏î‡∏ó‡∏µ‡πà 5
                label_text = f"L{display_level}"
                label_x = x_end + 15
                label_y = y_draw - 55
                
                cv2.putText(orig, label_text, (label_x, label_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                           LEVEL_COLORS[display_level], 3)
        
        fly_counts.append(total_expected if total_expected > 0 else tube_fly_count)
        tube_level_results.append(level_counts)
        
        # SCORE CALC
        score_per_level = []
        for lv in range(LEVEL_COUNT):
            score_per_level.append(level_counts[lv] * LEVEL_SCORES[lv])
        tube_level_scores.append(score_per_level)
    
    # SUMMARY
    total_flies = sum(fly_counts)
    all_flies_below_L1 = (total_flies > 0) and (flies_above_L1 == 0)
    
    return orig, all_flies_below_L1, total_flies, fly_counts, tube_level_results, tube_level_scores

# =========================
# PROCESS FRAME WITH YOLO (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà 5)
# =========================
def process_frame_with_yolo(img):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á OpenCV ‡πÅ‡∏•‡∏∞ YOLO ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏ß‡∏°‡∏ú‡∏•"""
    orig = img.copy()
    h_img, w_img = img.shape[:2]
    
    print("\n" + "="*60)
    print("PROCESSING WITH DUAL ALGORITHM (OpenCV + YOLO)")
    print("="*60)
    
    # BASELINE DETECTION
    roi_y_start = 0
    roi_y_end = 1000
    
    # TUBE POSITIONS
    tube_positions = []
    for i, cfg in enumerate(TUBE_CONFIGS):
        x_start = cfg['offset_from_left']
        x_end = x_start + cfg['width']
        tube_positions.append({
            'tube_num': i + 1,
            'x_start': x_start,
            'x_end': x_end
        })
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å 2 ‡∏ß‡∏¥‡∏ò‡∏µ
    opencv_results = []
    yolo_results = []
    combined_results = []
    
    fly_counts = []
    tube_level_results = []
    tube_level_scores = []
    flies_above_L1 = 0
    
    LEVEL_Y_DRAW = [y - 50 for y in LEVEL_Y_POSITIONS]
    
    for i, tube in enumerate(tube_positions):
        cfg = TUBE_CONFIGS[i]
        x_start = tube['x_start']
        x_end = tube['x_end']
        tube_y_start = roi_y_start + cfg['top_offset']
        tube_y_end = roi_y_end - cfg['bottom_offset']
        
        print(f"\n--- Tube {i+1} ---")
        
        # draw tube
        cv2.rectangle(orig, (x_start, tube_y_start), (x_end, tube_y_end), colors[i], 2)
        cv2.putText(orig, f"Tube {i+1}", (x_start + 50, tube_y_start - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, colors[i], 2)
        
        # extract ROI
        tube_roi = img[tube_y_start:tube_y_end, x_start:x_end]
        
        # ===== METHOD 1: OpenCV Threshold =====
        opencv_detections = []
        if tube_roi.size > 0:
            gray_roi = cv2.cvtColor(tube_roi, cv2.COLOR_BGR2GRAY)
            blur_roi = cv2.GaussianBlur(gray_roi, (3, 3), 0)
            th_roi = cv2.adaptiveThreshold(
                blur_roi, 255,
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY_INV, 17, 7
            )
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            th_clean = cv2.morphologyEx(th_roi, cv2.MORPH_OPEN, kernel, iterations=2)
            
            contours_fly, _ = cv2.findContours(
                th_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )[-2:]
            
            for cnt in contours_fly:
                area = cv2.contourArea(cnt)
                if 20 < area < 200:
                    fx, fy, fw, fh = cv2.boundingRect(cnt)
                    opencv_detections.append({
                        'x': x_start + fx,
                        'y': tube_y_start + fy,
                        'w': fw,
                        'h': fh,
                        'method': 'opencv'
                    })
        
        print(f"  OpenCV detected: {len(opencv_detections)} flies")
        
        # ===== METHOD 2: YOLO =====
        yolo_detections = []
        if yolo_model is not None and tube_roi.size > 0:
            crops = create_level_crops(tube_roi, tube_y_start, x_start)
            
            if len(crops) == 0:
                print(f"  Warning: No valid crops created for Tube {i+1}")
            else:
                all_tube_detections = []
                
                for crop_info in crops:
                    if crop_info['img'] is None or crop_info['img'].size == 0:
                        continue
                    
                    detections = detect_flies_yolo(crop_info, YOLO_CONF_THRESHOLD)
                    
                    for det in detections:
                        det['y'] += crop_info['y_start']
                        det['tube_y'] = det['y'] + tube_y_start
                        det['tube_x'] = det['x'] + x_start
                    
                    all_tube_detections.extend(detections)
                
                unique_detections = remove_duplicates(all_tube_detections, iou_threshold=0.4)
                
                for det in unique_detections:
                    yolo_detections.append({
                        'x': int(det['tube_x']),
                        'y': int(det['tube_y']),
                        'w': det['w'],
                        'h': det['h'],
                        'conf': det['conf'],
                        'method': 'yolo'
                    })
            
            print(f"  YOLO detected: {len(yolo_detections)} flies")
        
        # ===== COMBINE RESULTS =====
        # ‡∏£‡∏ß‡∏° detections ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á 2 ‡∏ß‡∏¥‡∏ò‡∏µ
        all_detections = opencv_detections + yolo_detections
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö: ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
        level_counts = [0] * LEVEL_COUNT
        
        for det in all_detections:
            # ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            color = (0, 0, 255)  # ‡πÅ‡∏î‡∏á
            thickness = 1
            
            cv2.rectangle(orig, (det['x'], det['y']),
                        (det['x'] + det['w'], det['y'] + det['h']), color, thickness)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì level
            cy = det['y'] + det['h'] // 2
            
            if cy < LEVEL_Y_DRAW[4]:
                flies_above_L1 += 1
            
            assigned = False
            for lv_idx in range(len(LEVEL_Y_DRAW)):
                if cy < LEVEL_Y_DRAW[lv_idx]:
                    level_counts[5 - lv_idx] += 1
                    assigned = True
                    break
            
            if not assigned:
                level_counts[0] += 1
        
        tube_fly_count = len(all_detections)
        print(f"  Combined total: {tube_fly_count} flies")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô
        total_expected = TOTAL_FLIES_PER_TUBE[i] if i < len(TOTAL_FLIES_PER_TUBE) else 0
        if total_expected > 0 and tube_fly_count < total_expected:
            unseen_flies = total_expected - tube_fly_count
            level_counts[5] += unseen_flies
            print(f"  Added {unseen_flies} unseen flies to L5")
        
        # draw level lines
        for lv_idx, y_draw in enumerate(LEVEL_Y_DRAW):
            display_level = 5 - lv_idx
            cv2.line(orig, (x_start, y_draw), (x_end, y_draw),
                    LEVEL_COLORS[display_level], LEVEL_THICKNESS)
            
            if i == 4:
                label_text = f"L{display_level}"
                label_x = x_end + 15
                label_y = y_draw - 55
                cv2.putText(orig, label_text, (label_x, label_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                           LEVEL_COLORS[display_level], 3)
        
        fly_counts.append(total_expected if total_expected > 0 else tube_fly_count)
        tube_level_results.append(level_counts)
        
        # SCORE CALC
        score_per_level = []
        for lv in range(LEVEL_COUNT):
            score_per_level.append(level_counts[lv] * LEVEL_SCORES[lv])
        tube_level_scores.append(score_per_level)
        
        opencv_results.append(len(opencv_detections))
        yolo_results.append(len(yolo_detections))
        combined_results.append(tube_fly_count)
    
    # SUMMARY
    total_flies = sum(fly_counts)
    all_flies_below_L1 = (total_flies > 0) and (flies_above_L1 == 0)
    
    print("\n" + "="*60)
    print("RESULTS SUMMARY")
    print("="*60)
    print(f"OpenCV detections per tube: {opencv_results}")
    print(f"YOLO detections per tube:   {yolo_results}")
    print(f"Combined total per tube:    {combined_results}")
    print(f"Grand total: {total_flies} flies")
    print("="*60 + "\n")
    
    return orig, all_flies_below_L1, total_flies, fly_counts, tube_level_results, tube_level_scores

# =========================
# CREATE GUI WITH SIDEBAR
# =========================
def create_gui_frame(orig, fly_counts, tube_level_results, tube_level_scores):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á GUI ‡∏û‡∏£‡πâ‡∏≠‡∏° Sidebar"""
    h_orig, w_orig = orig.shape[:2]
    
    # ‡∏´‡∏≤‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏≠‡∏î‡∏ó‡∏î‡∏•‡∏≠‡∏á
    min_x = min([cfg['offset_from_left'] for cfg in TUBE_CONFIGS]) - 50
    max_x = max([cfg['offset_from_left'] + cfg['width'] for cfg in TUBE_CONFIGS]) + 100
    roi_y_start = 0
    roi_y_end = 1000
    
    # ‡∏ï‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô ROI ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≠‡∏î
    cropped_orig = orig[roi_y_start:roi_y_end, min_x:max_x]
    h_crop, w_crop = cropped_orig.shape[:2]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° sidebar (‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß)
    new_img = np.ones((h_crop, w_crop + SIDEBAR_WIDTH, 3), dtype=np.uint8) * 255
    
    # ‡∏ß‡∏≤‡∏á sidebar
    new_img[:, :SIDEBAR_WIDTH] = SIDEBAR_COLOR
    
    # ‡∏ß‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß
    new_img[:h_crop, SIDEBAR_WIDTH:SIDEBAR_WIDTH+w_crop] = cropped_orig
    
    # =========================
    # DRAW TABLE ‡∏ö‡∏ô SIDEBAR
    # =========================
    table_x = 20
    table_y = 140
    row_h = 35
    left_w = 60
    col_w = 60
    font_scale = 0.65
    thick = 2
    header_gap = 5

    levels = ['L5','L4','L3','L2','L1','L0']
    tubes = [f'T{i+1}' for i in range(len(tube_level_results))]

    level_totals = []
    for c in range(len(tubes)):
        total = sum(tube_level_results[c])
        level_totals.append(total)

    table_w = left_w + col_w * len(tubes)
    table_h = row_h * (len(levels) + 2) + header_gap
    
    # Header box - Drosophila No.
    header_box_y = 30
    header_box_h = 80
    cv2.rectangle(new_img, (table_x, header_box_y+30), 
                  (table_x + table_w-140, header_box_y + header_box_h+30),
                  (0, 0, 0), -1)
    cv2.rectangle(new_img, 
                  (table_x, header_box_y+30), 
                  (table_x + table_w-140, header_box_y + header_box_h+30),
                  (255, 255, 255), 2)
    cv2.putText(new_img, "Drosophila No.", (table_x + 13, header_box_y + 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255, 255, 255), 2)

    # Table background
    cv2.rectangle(new_img, (table_x, table_y-row_h),
                  (table_x+table_w, table_y+table_h-25),
                  (30, 30, 30), -1)
    cv2.rectangle(new_img, (table_x, table_y-row_h),
                  (table_x+table_w, table_y+table_h-25),
                  (200, 200, 200), 2)

    # Horizontal lines
    cv2.line(new_img, (table_x, table_y + header_gap), 
             (table_x+table_w, table_y + header_gap), 
             (200,200,200), 2)

    for r in range(len(levels)):
        y_line = table_y + header_gap + (r+1)*row_h
        cv2.line(new_img, (table_x, y_line), 
                 (table_x+table_w, y_line), 
                 (100,100,100), 1)

    total_line_y = table_y + header_gap + (len(levels)+1)*row_h
    cv2.line(new_img, (table_x, total_line_y-row_h), 
             (table_x+table_w, total_line_y-row_h), 
             (200,200,200), 2)

    # Vertical lines
    cv2.line(new_img, (table_x+left_w, table_y-row_h), 
             (table_x+left_w, table_y+table_h-25), 
             (200,200,200), 2)

    for c in range(1, len(tubes)):
        x_line = table_x + left_w + c*col_w
        cv2.line(new_img, (x_line, table_y-row_h), 
                 (x_line, table_y+table_h-25), 
                 (100,100,100), 1)

    # Header row
    header_y = table_y - 10
    cv2.putText(new_img, "Tube", (table_x + 5, header_y),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    for i, t in enumerate(tubes):
        text_x = table_x + left_w + i*col_w + 15
        cv2.putText(new_img, t, (text_x, header_y),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    # Data rows
    for r, lvl in enumerate(levels):
        y = table_y + header_gap + (r+1)*row_h - 10
        
        level_index = 5 - r
        if level_index in LEVEL_COLORS:
            label_color = LEVEL_COLORS[level_index]
        else:
            label_color = (255, 255, 255)
        
        cv2.putText(new_img, lvl, (table_x + 15, y),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, label_color, thick)
        
        for c in range(len(tubes)):
            val = tube_level_results[c][level_index]
            text_x = table_x + left_w + c*col_w + 20
            cv2.putText(new_img, str(val), (text_x, y),
                        cv2.FONT_HERSHEY_SIMPLEX, font_scale, label_color, thick)

    # Total row
    total_y = table_y + header_gap + (len(levels)+1)*row_h - 10
    cv2.putText(new_img, "Total", (table_x + 5, total_y+5),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    for c in range(len(tubes)):
        cv2.putText(new_img, str(level_totals[c]),
                    (table_x + left_w + c*col_w + 20, total_y+5),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    # =========================
    # DRAW SCORE TABLE
    # =========================
    score_totals = []
    for c in range(len(tubes)):
        total = sum(tube_level_scores[c])
        score_totals.append(total)

    score_table_y = table_y + table_h + 100

    # Header box - Score
    score_header_y = score_table_y - 110
    cv2.rectangle(new_img, (table_x, score_header_y+150), 
                  (table_x + table_w-260, score_header_y + 30),
                  (0, 0, 0), -1)
    cv2.rectangle(new_img, 
                  (table_x, score_header_y+150), 
                  (table_x + table_w-260, score_header_y + 30),
                  (255, 255, 255), 2)
    cv2.putText(new_img, "Score", (table_x +13, score_header_y + 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255, 255, 255), 2)

    # Score table background
    cv2.rectangle(new_img, (table_x, score_table_y-row_h),
                  (table_x+table_w, score_table_y+table_h-25),
                  (30, 30, 30), -1)
    cv2.rectangle(new_img, (table_x, score_table_y-row_h),
                  (table_x+table_w, score_table_y+table_h-25),
                  (200, 200, 200), 2)

    cv2.line(new_img, (table_x, score_table_y + header_gap), 
             (table_x+table_w, score_table_y + header_gap), 
             (200,200,200), 2)

    for r in range(len(levels)):
        y_line = score_table_y + header_gap + (r+1)*row_h
        cv2.line(new_img, (table_x, y_line), 
                 (table_x+table_w, y_line), 
                 (100,100,100), 1)

    score_total_line_y = score_table_y + header_gap + (len(levels)+1)*row_h
    cv2.line(new_img, (table_x, score_total_line_y-row_h), 
             (table_x+table_w, score_total_line_y-row_h), 
             (200,200,200), 2)

    cv2.line(new_img, (table_x+left_w, score_table_y-row_h), 
             (table_x+left_w, score_table_y+table_h-25), 
             (200,200,200), 2)

    for c in range(1, len(tubes)):
        x_line = table_x + left_w + c*col_w
        cv2.line(new_img, (x_line, score_table_y-row_h), 
                 (x_line, score_table_y+table_h-25), 
                 (100,100,100), 1)
        
    header_y = score_table_y - 10
    cv2.putText(new_img, "Tube", (table_x + 5, header_y),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    for i, t in enumerate(tubes):
        cv2.putText(new_img, t,
                    (table_x + left_w + i*col_w + 15, header_y),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    for r, lvl in enumerate(levels):
        y = score_table_y + header_gap + (r+1)*row_h - 10
    
        level_index = 5 - r
        if level_index in LEVEL_COLORS:
            label_color = LEVEL_COLORS[level_index]
        else:
            label_color = (255, 255, 255)
        
        cv2.putText(new_img, lvl, (table_x + 15, y),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, label_color, thick)
        
        for c in range(len(tubes)):
            score_val = tube_level_scores[c][5-r]
            cv2.putText(new_img, str(score_val),
                        (table_x + left_w + c*col_w + 20, y),
                        cv2.FONT_HERSHEY_SIMPLEX, font_scale, label_color, thick)

    score_total_y = score_table_y + header_gap + (len(levels)+1)*row_h - 10
    cv2.putText(new_img, "Total", (table_x + 5, score_total_y+5),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)

    for c in range(len(tubes)):
        cv2.putText(new_img, str(score_totals[c]),
                    (table_x + left_w + c*col_w + 20, score_total_y+5),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thick)
    
    return new_img

# ========================= 
# SAVE SNAPSHOT FUNCTION
# ========================= 
def save_snapshot_with_gui(frame, timestamp, total_flies, fly_counts, level_results, level_scores, snapshot_type="trigger"):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏° GUI"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á GUI frame
    gui_frame = create_gui_frame(frame, fly_counts, level_results, level_scores)
    
    filename = f"{SNAPSHOT_FOLDER}{snapshot_type}_{timestamp}_flies{total_flies}.jpg"
    cv2.imwrite(filename, gui_frame)
    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏° GUI: {filename}")
    return filename


# ========================= 
# MAIN PROGRAM
# ========================= 
def main():
    global waiting_for_5sec_capture, capture_5sec_time
    
    # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    cap = cv2.VideoCapture(1)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    
    if not cap.isOpened():
        print("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
        return
    
    # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ESP32
    ser = None
    try:
        ser = serial.Serial(ESP32_PORT, ESP32_BAUDRATE, timeout=1)
        time.sleep(2)
        print(f"‚úì ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ESP32 ‡∏ó‡∏µ‡πà {ESP32_PORT} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        esp32_thread = threading.Thread(target=read_esp32, args=(ser, trigger_queue), daemon=True)
        esp32_thread.start()
    except Exception as e:
        print(f"‚úó ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ESP32: {e}")
        print("‚úì ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ ESP32 (‡∏Å‡∏î 't' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢)")
        ser = None
    
    print(f"\n{'='*50}")
    print(f"‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û: {SNAPSHOT_FOLDER}")
    print(f"{'='*50}")
    print("‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:")
    print("  - ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")
    print("  - ‡∏Å‡∏î 't' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ESP32)")
    print("  - ESP32 ‡∏™‡πà‡∏á 'CAPTURE' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡πà‡∏≤‡∏¢")
    print(f"{'='*50}\n")
    
    frame_count = 0
    snapshot_count = 0
    last_trigger_info = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô frame")
            break
        
        frame_count += 1
        current_time = time.time()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á display frame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠)
        display_frame = frame.copy()
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
        h, w = display_frame.shape[:2]
        status_color = (0, 255, 0)
        status_text = "Live Camera - Ready"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏≠‡∏Ñ‡∏£‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if waiting_for_5sec_capture:
            elapsed = current_time - capture_5sec_time
            remaining = WAIT_DURATION - elapsed
            
            if remaining > 0:
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏ñ‡∏≠‡∏¢‡∏´‡∏•‡∏±‡∏á
                status_color = (0, 165, 255)
                status_text = f"Waiting for 5s capture: {remaining:.1f}s"
            else:
                # ‡∏Ñ‡∏£‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ - ‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                print(f"\n{'='*50}")
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ‡∏Ñ‡∏£‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏Ñ‡∏õ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ DUAL ALGORITHM...")
                
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• frame ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á OpenCV ‡πÅ‡∏•‡∏∞ YOLO
                processed_frame, all_below_L1, total_flies, fly_counts, level_results, level_scores = process_frame_with_yolo(frame)
                
                print(f"Total flies: {total_flies}")
                print(f"Flies per tube: {fly_counts}")
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏° GUI
                timestamp_5sec = datetime.now().strftime("%Y%m%d_%H%M%S")
                snapshot_count += 1
                save_snapshot_with_gui(processed_frame, timestamp_5sec, total_flies, fly_counts, 
                                      level_results, level_scores, snapshot_type=f"5sec_{snapshot_count:03d}")
                
                print(f"‚úì ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà 5 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
                print(f"{'='*50}\n")
                
                # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
                waiting_for_5sec_capture = False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏à‡∏≤‡∏Å ESP32
        if not trigger_queue.empty():
            trigger_queue.get()
            trigger_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            print(f"\n{'='*50}")
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ñ‡πà‡∏≤‡∏¢! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• frame ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            processed_frame, all_below_L1, total_flies, fly_counts, level_results, level_scores = process_frame(frame)
            
            print(f"Total flies: {total_flies}")
            print(f"Flies per tube: {fly_counts}")
            print(f"All flies below L1: {all_below_L1}")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏° GUI
            snapshot_count += 1
            save_snapshot_with_gui(processed_frame, trigger_timestamp, total_flies, fly_counts, 
                                  level_results, level_scores, snapshot_type=f"trigger_{snapshot_count:03d}")
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            last_trigger_info = {
                'time': datetime.now().strftime('%H:%M:%S'),
                'total_flies': total_flies,
                'all_below_L1': all_below_L1
            }
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏ñ‡πâ‡∏≤‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ï‡πâ L1 ‚Üí ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏≠ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
            if all_below_L1:
                print(">>> ‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ï‡πâ‡πÄ‡∏™‡πâ‡∏ô L1 - ‡∏à‡∏∞‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ!")
                waiting_for_5sec_capture = True
                capture_5sec_time = current_time
            else:
                if total_flies == 0:
                    print(">>> ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á - ‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏¥‡πà‡∏°")
                else:
                    print(">>> ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡πÄ‡∏™‡πâ‡∏ô L1 - ‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏¥‡πà‡∏°")
                
                # ‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ ESP32 ‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏≤‡∏∞‡πÅ‡∏°‡∏•‡∏á‡∏ß‡∏±‡∏ô
                if ser:
                    try:
                        ser.write(b'TAP\n')
                        print(">>> ‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì 'TAP' ‡πÑ‡∏õ‡∏¢‡∏±‡∏á ESP32 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ñ‡∏≤‡∏∞‡πÅ‡∏°‡∏•‡∏á‡∏ß‡∏±‡∏ô!")
                    except Exception as e:
                        print(f"Error sending TAP command: {e}")
            
            print(f"{'='*50}\n")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô display frame
        cv2.putText(display_frame, status_text, (w - 450, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
        
        if last_trigger_info:
            result_text = f"Last: {last_trigger_info['time']} | Flies: {last_trigger_info['total_flies']}"
            result_color = (0, 255, 0) if last_trigger_info['all_below_L1'] else (0, 165, 255)
            cv2.putText(display_frame, result_text, (20, h - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, result_color, 2)
        
        cv2.putText(display_frame, f"Snapshots: {snapshot_count}", (w - 300, 80),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        scale_percent = 50
        width = int(display_frame.shape[1] * scale_percent / 100)
        height = int(display_frame.shape[0] * scale_percent / 100)
        resized = cv2.resize(display_frame, (width, height))
        
        cv2.imshow("Fly Counter - Live Camera", resized)
        
        # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏µ‡∏¢‡πå‡∏ö‡∏≠‡∏£‡πå‡∏î
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord('t'):
            # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì
            trigger_queue.put(True)
    
    # ‡∏õ‡∏¥‡∏î‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á
    print("\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
    cap.release()
    cv2.destroyAllWindows()
    if ser:
        ser.close()
    
    print(f"\n{'='*50}")
    print(f"‡∏™‡∏£‡∏∏‡∏õ:")
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô frames ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á: {frame_count}")
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {snapshot_count}")
    print(f"‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û: {SNAPSHOT_FOLDER}")
    print(f"{'='*50}")

if __name__ == "__main__":
    main()
